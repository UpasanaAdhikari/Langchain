{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Runnable sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from dotenv import load_dotenv\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "API_KEY=os.getenv(\"API_KEY\")\n",
    "api=os.getenv('mapi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema.runnable import RunnableSequence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatGoogleGenerativeAI(\n",
    "    model =\"gemini-2.5-flash\",\n",
    "    google_api_key = API_KEY\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt=PromptTemplate(\n",
    "    template=\"Tell me a joke {joke}\",\n",
    "    input_variables=['joke']\n",
    ")\n",
    "parser =StrOutputParser()\n",
    "chain= RunnableSequence(prompt,llm,parser)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Why don scientists not trust atoms?\n",
      "\n",
      "Because they make up everything!\n"
     ]
    }
   ],
   "source": [
    "print(chain.invoke({\"funny\"}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt1=PromptTemplate(\n",
    "    template=\"Explain the joke {text}\",\n",
    "    input_variables=['text']\n",
    ")\n",
    "parser =StrOutputParser()\n",
    "chain= RunnableSequence(prompt,llm,parser,prompt1,llm,parser)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This joke plays on the double meaning of the phrase \"make up everything\":\n",
      "\n",
      "1.  **Literal/Scientific Meaning:** In science, atoms are indeed the fundamental building blocks that **constitute** or **form** everything in the universe. Everything is literally \"made up of\" atoms.\n",
      "\n",
      "2.  **Figurative/Colloquial Meaning (the pun):** To \"make up\" something can also mean to **invent, fabricate, or lie about something**. For example, \"He made up a story\" means he lied.\n",
      "\n",
      "The humor comes from applying the *second* meaning (lying/fabricating) to atoms, even though the *first* meaning (being the building blocks of everything) is the scientific truth. If atoms \"make up\" everything in the sense of \"lying about everything,\" then you certainly wouldn't trust them!\n"
     ]
    }
   ],
   "source": [
    "print(chain.invoke({\"funny\"}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Runnable parallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_mistralai.chat_models import ChatMistralAI\n",
    "\n",
    "llm= ChatGoogleGenerativeAI(\n",
    "    model =\"gemini-2.5-flash\",\n",
    "    google_api_key = API_KEY\n",
    ")\n",
    "llm2=ChatMistralAI(\n",
    "    model=\"mistral-small-latest\",  \n",
    "    mistral_api_key=api,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema.runnable import RunnableParallel\n",
    "\n",
    "prompt1= PromptTemplate(\n",
    "    template=\"Genarate tweet about topic {topic}\",\n",
    "    input_variables=['topic']\n",
    ")\n",
    "prompt2= PromptTemplate(\n",
    "    template=\"Genarate linkedin post about topic {topic}\",\n",
    "    input_variables=['topic']\n",
    ")\n",
    "parser=StrOutputParser()\n",
    "parallel=RunnableParallel({\n",
    "    'tweet':RunnableSequence(prompt1,llm,parser),\n",
    "    'post':RunnableSequence(prompt2,llm,parser)\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "result=parallel.invoke({\"topic\":\"AI\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are a few options for a tweet about AI, covering different angles:\n",
      "\n",
      "**Option 1 (Optimistic & Forward-Looking):**\n",
      "> The future is now! ðŸ¤– AI is revolutionizing industries, from healthcare to education, and unlocking new possibilities. What innovation excites you most? âœ¨ #AI #ArtificialIntelligence #FutureTech\n",
      "\n",
      "**Option 2 (Thought-Provoking & Ethical):**\n",
      "> As AI rapidly advances, so do the conversations around ethics, bias, and job displacement. How do we ensure a responsible and equitable AI future? ðŸ¤” Share your thoughts! #AIEthics #FutureOfWork\n",
      "\n",
      "**Option 3 (Concise & Engaging Question):**\n",
      "> AI is everywhere! From recommending your next show to powering self-driving cars. What's one surprising way AI has impacted your life recently? Share below! ðŸ‘‡ #AIImpact\n",
      "\n",
      "**Option 4 (Focus on Transformation):**\n",
      "> The AI revolution is in full swing! ðŸ§  From automating tasks to solving complex problems, artificial intelligence is reshaping our world at an incredible pace. #TechInnovation #DigitalTransformation\n",
      "\n",
      "**Option 5 (Short & Punchy):**\n",
      "> AI: Building a smarter, more efficient world, one algorithm at a time. The possibilities are endless! ðŸš€ #ArtificialIntelligence #Innovation\n"
     ]
    }
   ],
   "source": [
    "print(result['tweet'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are a few options for a LinkedIn post about AI, catering to different angles and tones. Choose the one that best fits your personal brand and message!\n",
      "\n",
      "---\n",
      "\n",
      "**Option 1: The Optimistic & Future-Focused Post**\n",
      "\n",
      "ðŸš€ **AI isn't just a buzzword; it's the engine driving the next wave of innovation across every industry.**\n",
      "\n",
      "From streamlining operations to unlocking unprecedented insights and personalizing experiences, Artificial Intelligence is reshaping how we work, live, and create. It's no longer a futuristic concept but a powerful tool available today.\n",
      "\n",
      "The key now is not just *if* we adopt AI, but *how* we integrate it responsibly and strategically to augment human potential.\n",
      "\n",
      "What industry do you believe AI will revolutionize most in the next 5 years, and why? Share your thoughts below!\n",
      "\n",
      "#AI #ArtificialIntelligence #Innovation #FutureOfWork #DigitalTransformation #TechTrends\n",
      "\n",
      "---\n",
      "\n",
      "**Option 2: The Practical & Skill-Oriented Post**\n",
      "\n",
      "Feeling overwhelmed by the rapid pace of AI advancements? You're not alone.\n",
      "\n",
      "Instead of fearing the unknown, let's focus on harnessing AI's power. It's less about replacing jobs and more about augmenting human capabilities.\n",
      "\n",
      "Here are a few practical steps we can all take:\n",
      "*   **Educate Yourself:** Understand the basics of how AI works and its applications.\n",
      "*   **Experiment:** Play around with AI tools (like ChatGPT, Midjourney, etc.) to see their potential.\n",
      "*   **Identify Opportunities:** Look for ways AI can automate mundane tasks in your role, freeing you for more strategic work.\n",
      "*   **Develop \"Human\" Skills:** Focus on creativity, critical thinking, emotional intelligence, and complex problem-solving â€“ areas where humans excel.\n",
      "\n",
      "How are you personally engaging with AI to stay ahead in your career or business?\n",
      "\n",
      "#AIskills #Upskilling #FutureReady #CareerDevelopment #Learning #TechTrends\n",
      "\n",
      "---\n",
      "\n",
      "**Option 3: The Thought-Provoking & Ethical Post**\n",
      "\n",
      "ðŸ¤– As AI rapidly evolves, the conversation needs to shift beyond just \"what it can do\" to \"how we ensure it serves humanity responsibly.\"\n",
      "\n",
      "The ethical considerations around AI â€“ bias in algorithms, data privacy, job displacement, and the need for transparency â€“ are paramount. Building an AI-powered future requires not just technological brilliance but also deep ethical foresight and collaborative governance.\n",
      "\n",
      "How do we balance the incredible potential of AI with the critical need for responsible development and deployment? What ethical considerations are top of mind for you?\n",
      "\n",
      "#AIethics #ResponsibleAI #HumanAI #Innovation #FutureOfWork #Technology #Ethics\n",
      "\n",
      "---\n",
      "\n",
      "**Option 4: The Short & Engaging Question Post**\n",
      "\n",
      "Quick poll! ðŸ’¡\n",
      "\n",
      "Are you feeling more **excited** or **cautious** about the rapid advancements in Artificial Intelligence?\n",
      "\n",
      "Let me know your perspective and why in the comments! ðŸ‘‡\n",
      "\n",
      "#AI #TechPoll #FutureOfTech #Innovation #Discussion\n",
      "\n",
      "---\n",
      "\n",
      "**Remember to:**\n",
      "*   **Add an image or video** to your post for better engagement (e.g., a relevant AI infographic, a professional headshot, or a short animation).\n",
      "*   **Engage with comments** you receive to foster discussion.\n",
      "*   **Tailor the post** slightly to your specific industry or personal experience if you wish.\n"
     ]
    }
   ],
   "source": [
    "print(result['post'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Runnable Pass through\n",
    "- return input as ouput without modifying\n",
    "- useful for testing, skipping steps, or keeping workflow uniform."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema.runnable import RunnablePassthrough\n",
    "\n",
    "prompt=PromptTemplate(\n",
    "    template=\"Tell me a joke {joke}\",\n",
    "    input_variables=['joke']\n",
    ")\n",
    "parser =StrOutputParser()\n",
    "chain= RunnableSequence(prompt,llm,parser)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt1=PromptTemplate(\n",
    "    template=\"Explain the joke {text}\",\n",
    "    input_variables=['text']\n",
    ")\n",
    "parser =StrOutputParser()\n",
    "j_chain= RunnableParallel({\n",
    "    \"joke\":RunnablePassthrough(),\n",
    "    \"Explation\": RunnableSequence(prompt1,llm,parser)\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_chain=RunnableSequence(chain,j_chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'joke': 'Why did the atom get pulled over?\\n\\nBecause it had a **charge**!', 'Explation': 'This joke is a pun that plays on the double meaning of the word \"charge\"!\\n\\nHere\\'s the breakdown:\\n\\n1.  **Meaning 1 (Legal/Common Usage):** When a person (or a car) gets \"pulled over\" by the police, it\\'s often because they\\'ve committed an offense, and they might face a **legal charge** (an accusation of a crime, e.g., \"charged with speeding\" or \"charged with reckless driving\"). This is the expected meaning when someone is pulled over.\\n\\n2.  **Meaning 2 (Scientific/Physics):** In science, an **atom** can have an **electrical charge**.\\n    *   Atoms are made of protons (positive charge), neutrons (no charge), and electrons (negative charge).\\n    *   If an atom gains or loses electrons, it becomes an ion and has an overall positive or negative \"charge.\" A neutral atom has no net charge.\\n\\nThe humor comes from the unexpected twist: you expect the answer to be a legal \"charge\" because it was \"pulled over,\" but the punchline delivers the scientific \"charge\" that applies specifically to an atom. It\\'s a classic science pun!'}\n"
     ]
    }
   ],
   "source": [
    "print(final_chain.invoke({\"joke\":\"Science\"}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Runnable Lambda\n",
    "- you wrap any simple Python function (or lambda) so it can be treated like a Runnable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema.runnable import RunnableLambda\n",
    "\n",
    "prompt=PromptTemplate(\n",
    "    template=\"Tell me a joke {joke}\",\n",
    "    input_variables=['joke']\n",
    ")\n",
    "parser =StrOutputParser()\n",
    "chain= RunnableSequence(prompt,llm,parser)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_count(text):\n",
    "    return len(text.split())\n",
    "\"\"\" \n",
    "x = \"apple,banana,orange\"\n",
    "x.split(\",\")  # Output: ['apple', 'banana', 'orange']\n",
    "\n",
    "len(\"Hello\")       # Output: 5 (characters)\n",
    "len([\"a\",\"b\",\"c\"]) # Output: 3 (elements)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "parser =StrOutputParser()\n",
    "j_chain= RunnableParallel({\n",
    "    \"joke\":RunnablePassthrough(),\n",
    "    \"length\": RunnableLambda(word_count) # can be RunnableLambda (lambda x :x len(x.split()))\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_chain=RunnableSequence(chain,j_chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "result= final_chain.invoke({'joke':'AI'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_result=\"\"\"{}\\nword count {}\"\"\".format (result['joke'],result['length'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Okay, here's one for you!\n",
      "\n",
      "Why did the scarecrow win an award?\n",
      "... Because he was outstanding in his field!\n",
      "word count 20\n"
     ]
    }
   ],
   "source": [
    "print(final_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conditional Runnable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema.runnable import RunnableBranch\n",
    "\n",
    "prompt=PromptTemplate(\n",
    "    template=\"write a detail in a topic {topic}\",\n",
    "    input_variables=['topic']\n",
    ")\n",
    "prompt2=PromptTemplate(\n",
    "    template=\"Summarize the following text{text}\",\n",
    "    input_variables=['text']\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "report_gen_chain=RunnableSequence(prompt,llm,parser)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "branch_chain=RunnableBranch(\n",
    "    (lambda x: len(x.split())>200, RunnableSequence(prompt2,llm,parser)),\n",
    "    RunnablePassthrough()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_chain=RunnableSequence(report_gen_chain,branch_chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Battle of Stalingrad (August 1942 â€“ February 1943) was a pivotal and brutal turning point on World War II's Eastern Front, shattering the myth of German invincibility.\n",
      "\n",
      "Germany's objective (Operation Blau) was to capture the oil-rich Caucasus and secure Stalingrad, a strategic industrial city on the Volga River, which also held symbolic importance bearing Stalin's name. The battle began with a devastating Luftwaffe bombing on August 23, 1942, reducing the city to rubble, which paradoxically made subsequent urban combat, dubbed \"Rattenkrieg\" (Rat War), even more horrific. Fighting devolved into brutal house-to-house, room-to-room combat, particularly around key industrial complexes, resulting in immense casualties for both sides. German Panzer divisions were largely ineffective in the ruins.\n",
      "\n",
      "While the Germans were bogged down, Soviet Marshal Georgy Zhukov meticulously planned \"Operation Uranus,\" a massive pincer movement launched on November 19, 1942. This operation swiftly encircled the entire German Sixth Armyâ€”approximately 300,000 menâ€”by November 23. Hitler's refusal to allow a breakout, coupled with a failed air supply bridge and a relief attempt (Operation Winter Storm), led to catastrophic suffering for the trapped German soldiers, who faced starvation, extreme cold, and disease. General Paulus finally surrendered on February 2, 1943.\n",
      "\n",
      "The battle resulted in catastrophic casualties (Axis: ~1 million; Soviets: >1.1 million). It delivered a profound psychological blow to Germany, shifted the strategic initiative definitively to the Soviets, and marked the beginning of Germany's long retreat from the East, epitomizing the concept of total war.\n"
     ]
    }
   ],
   "source": [
    "print(final_chain.invoke({\"topic\":\"WW2\"}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chatbot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
